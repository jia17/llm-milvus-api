import streamlit as st
import time
import json
import io
from pathlib import Path
from typing import List, Dict, Any, Optional
import sys
import os
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent.parent))

from src.graph.workflow import RAGWorkflow
from src.utils.helpers import get_config, PerformanceTimer, clean_filename
from src.conversation.session_manager import SessionManager
from src.conversation.models import ChatMessage
import requests
import json
from urllib.parse import urljoin


# é¡µé¢é…ç½®
st.set_page_config(
    page_title=get_config("web.title", "æ™ºèƒ½é—®ç­”ç³»ç»Ÿ"),
    page_icon="ğŸ¤–",
    layout=get_config("web.page_config.layout", "wide"),
    initial_sidebar_state="expanded"
)


@st.cache_resource
def initialize_system():
    """åˆå§‹åŒ–ç³»ç»Ÿç»„ä»¶ï¼ˆä½¿ç”¨ç¼“å­˜é¿å…é‡å¤åˆå§‹åŒ–ï¼‰"""
    try:
        # åˆå§‹åŒ–LangGraphå·¥ä½œæµ
        workflow = RAGWorkflow()
        if not workflow.initialize_services():
            st.error("âš ï¸ LangGraphå·¥ä½œæµåˆå§‹åŒ–å¤±è´¥")
            return None
        
        # åˆå§‹åŒ–ä¼šè¯ç®¡ç†å™¨
        session_manager = SessionManager(
            enable_compression=get_config("conversation.enable_compression", True),
            enable_checkpoints=get_config("conversation.enable_checkpoints", True)
        )
        
        return {
            "workflow": workflow,
            "vector_store": workflow.vector_store,
            "retriever": workflow.hybrid_retriever,
            "session_manager": session_manager
        }
        
    except Exception as e:
        st.error(f"âŒ ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {str(e)}")
        return None


def render_sidebar():
    """æ¸²æŸ“ä¾§è¾¹æ """
    with st.sidebar:
        st.title("ğŸ¤– æ™ºèƒ½é—®ç­”ç³»ç»Ÿ")
        st.markdown("---")
        
        # ç³»ç»ŸçŠ¶æ€
        st.subheader("ğŸ“Š ç³»ç»ŸçŠ¶æ€")
        
        components = st.session_state.get("components")
        if components:
            try:
                stats = fetch_knowledge_stats(components["vector_store"])
                st.success("ğŸŸ¢ ç³»ç»Ÿæ­£å¸¸")
                st.metric("ğŸ“š æ–‡æ¡£å—æ•°", stats.get("total_chunks", 0))
                st.metric("ğŸ”¢ å‘é‡ç»´åº¦", stats.get("dimension", "N/A"))
            except:
                st.warning("ğŸŸ¡ ç³»ç»Ÿè¿æ¥å¼‚å¸¸")
        else:
            st.error("ğŸ”´ ç³»ç»Ÿæœªåˆå§‹åŒ–")
        
        st.markdown("---")
        
        # è®¾ç½®é€‰é¡¹
        st.subheader("âš™ï¸ è®¾ç½®")
        
        # æ£€ç´¢å‚æ•°
        top_k = st.slider("æ£€ç´¢æ–‡æ¡£æ•°é‡", 1, 20, 5)
        st.session_state["top_k"] = top_k
        
        method = st.selectbox(
            "æ£€ç´¢æ–¹æ³•",
            ["hybrid", "dense", "sparse"],
            index=0,
            format_func=lambda x: {
                "hybrid": "ğŸ”„ æ··åˆæ£€ç´¢",
                "dense": "ğŸ¯ ç¨ å¯†å‘é‡",
                "sparse": "ğŸ” ç¨€ç–å…³é”®è¯"
            }[x]
        )
        st.session_state["retrieval_method"] = method
        
        # ç”Ÿæˆå‚æ•°
        temperature = st.slider("å›ç­”åˆ›é€ æ€§", 0.0, 1.0, 0.7, step=0.1)
        st.session_state["temperature"] = temperature
        
        st.markdown("---")
        
        # æ“ä½œæŒ‰é’®
        st.subheader("ğŸ”§ æ“ä½œ")
        
        if st.button("ğŸ’¬ ä¼šè¯ç®¡ç†", help="ç®¡ç†å¯¹è¯ä¼šè¯"):
            st.session_state["show_session_manager"] = True
        
        if st.button("ğŸ“Š æŸ¥çœ‹ç»Ÿè®¡", help="æŸ¥çœ‹è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯"):
            st.session_state["show_stats"] = True
        
        st.markdown("---")
        st.markdown("### ğŸ“– ä½¿ç”¨æŒ‡å—")
        st.markdown("""
        1. **ä¸Šä¼ æ–‡æ¡£**: æ”¯æŒPDFã€TXTã€MDã€DOCXæ ¼å¼
        2. **æé—®**: åŸºäºå·²ä¸Šä¼ æ–‡æ¡£å†…å®¹æé—®
        3. **èŠå¤©**: æ™®é€šå¯¹è¯æ¨¡å¼
        4. **è®¾ç½®**: è°ƒæ•´æ£€ç´¢å’Œç”Ÿæˆå‚æ•°
        """)


def render_upload_section():
    """æ¸²æŸ“æ–‡æ¡£ä¸Šä¼ åŒºåŸŸ"""
    st.header("ğŸ“¤ æ–‡æ¡£ä¸Šä¼ ")
    
    components = st.session_state.get("components")
    if not components:
        st.error("âš ï¸ ç³»ç»Ÿæœªå°±ç»ªï¼Œæ— æ³•ä¸Šä¼ æ–‡æ¡£")
        return
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        uploaded_files = st.file_uploader(
            "é€‰æ‹©æ–‡æ¡£æ–‡ä»¶",
            type=['pdf', 'txt', 'md', 'docx'],
            accept_multiple_files=True,
            help="æ”¯æŒPDFã€TXTã€MDã€DOCXæ ¼å¼ï¼Œå•æ–‡ä»¶æœ€å¤§10MB"
        )
    
    with col2:
        st.info(f"""
        ğŸ“‹ **æ”¯æŒæ ¼å¼**
        - PDFæ–‡æ¡£
        - TXTæ–‡æœ¬
        - Markdownæ–‡ä»¶
        - Wordæ–‡æ¡£ (DOCX)
        
        ğŸ“ **æ–‡ä»¶é™åˆ¶**
        - æœ€å¤§å¤§å°: 10MB
        - æ‰¹é‡ä¸Šä¼ : æ”¯æŒ
        """)
    
    if uploaded_files:
        if st.button("ğŸš€ å¼€å§‹ä¸Šä¼ ", type="primary"):
            upload_progress = st.progress(0)
            status_container = st.container()
            
            total_files = len(uploaded_files)
            success_count = 0
            
            for i, uploaded_file in enumerate(uploaded_files):
                try:
                    # æ›´æ–°è¿›åº¦
                    upload_progress.progress((i + 1) / total_files)
                    
                    with status_container:
                        st.info(f"ğŸ“¤ å¤„ç†æ–‡ä»¶: {uploaded_file.name}")
                    
                    # ä¿å­˜ä¸´æ—¶æ–‡ä»¶
                    file_content = uploaded_file.read()
                    file_path = Path("temp") / clean_filename(uploaded_file.name)
                    file_path.parent.mkdir(exist_ok=True)
                    
                    with open(file_path, "wb") as f:
                        f.write(file_content)
                    
                    # å¤„ç†æ–‡æ¡£
                    with st.spinner(f"å¤„ç† {uploaded_file.name}..."):
                        # åŠ è½½å¹¶åˆ†å—
                        chunks = components["workflow"].document_loader.load_and_chunk_document(str(file_path))
                        
                        # ç”ŸæˆåµŒå…¥
                        texts = [chunk.content for chunk in chunks]
                        embedding_result = components["workflow"].embedding_manager.embed_documents(texts)
                        
                        # æ’å…¥æ•°æ®åº“
                        insert_result = components["workflow"].vector_store.insert_documents(
                            chunks, embedding_result.embeddings
                        )
                        
                        if insert_result.success:
                            success_count += 1
                            with status_container:
                                st.success(f"âœ… {uploaded_file.name}: {len(chunks)} ä¸ªæ–‡æ¡£å—")
                        else:
                            with status_container:
                                st.error(f"âŒ {uploaded_file.name}: {insert_result.error}")
                    
                    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                    try:
                        file_path.unlink()
                    except:
                        pass
                
                except Exception as e:
                    with status_container:
                        st.error(f"âŒ {uploaded_file.name}: {str(e)}")
            
            # å®Œæˆä¸Šä¼ 
            upload_progress.progress(1.0)
            
            if success_count > 0:
                st.success(f"ğŸ‰ ä¸Šä¼ å®Œæˆ! æˆåŠŸå¤„ç† {success_count}/{total_files} ä¸ªæ–‡ä»¶")
                
            else:
                st.error("âŒ æ²¡æœ‰æ–‡ä»¶æˆåŠŸä¸Šä¼ ")


def render_query_section():
    """æ¸²æŸ“é—®ç­”æŸ¥è¯¢åŒºåŸŸ"""
    st.header("ğŸ” æ™ºèƒ½é—®ç­”")
    
    components = st.session_state.get("components")
    if not components:
        st.error("âš ï¸ ç³»ç»Ÿæœªå°±ç»ªï¼Œæ— æ³•è¿›è¡ŒæŸ¥è¯¢")
        return
    
    # é—®é¢˜è¾“å…¥
    col1, col2 = st.columns([4, 1])
    
    with col1:
        question = st.text_input(
            "è¯·è¾“å…¥æ‚¨çš„é—®é¢˜:",
            placeholder="ä¾‹å¦‚: RAGæŠ€æœ¯çš„ä¼˜åŠ¿æ˜¯ä»€ä¹ˆï¼Ÿ",
            key="question_input"
        )
    
    with col2:
        query_button = st.button("ğŸ” æé—®", type="primary", disabled=not question.strip())
    
    # å¤„ç†æŸ¥è¯¢
    if query_button and question.strip():
        with st.spinner("ğŸ¤” æ€è€ƒä¸­..."):
            try:
                # è·å–å‚æ•°
                top_k = st.session_state.get("top_k", 5)
                method = st.session_state.get("retrieval_method", "hybrid")
                temperature = st.session_state.get("temperature", 0.7)
                
                start_time = time.time()
                
                # æ£€ç´¢
                retrieval_result = components["retriever"].search(
                    query=question,
                    top_k=top_k,
                    method=method
                )
                
                # ç”Ÿæˆå›ç­”
                generation_result = components["generator"].generate_answer(
                    question=question,
                    retrieval_result=retrieval_result,
                    temperature=temperature
                )
                
                total_time = time.time() - start_time
                
                # æ˜¾ç¤ºç»“æœ
                st.markdown("### ğŸ¤– AIå›ç­”")
                
                # å›ç­”å†…å®¹
                answer_container = st.container()
                with answer_container:
                    st.markdown(f"**{generation_result.answer}**")
                
                # æ€§èƒ½æŒ‡æ ‡
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.metric("â±ï¸ æ€»è€—æ—¶", f"{total_time:.2f}s")
                with col2:
                    st.metric("ğŸ” æ£€ç´¢è€—æ—¶", f"{retrieval_result.retrieval_time:.2f}s")
                with col3:
                    st.metric("ğŸ¯ ç”Ÿæˆè€—æ—¶", f"{generation_result.generation_time:.2f}s")
                with col4:
                    st.metric("ğŸ“š å‚è€ƒæ–‡æ¡£", len(generation_result.sources))
                
                # å‚è€ƒæ–‡æ¡£
                if generation_result.sources:
                    st.markdown("### ğŸ“– å‚è€ƒæ–‡æ¡£")
                    
                    for i, source in enumerate(generation_result.sources, 1):
                        with st.expander(f"ğŸ“„ æ–‡æ¡£ {i} (ç›¸ä¼¼åº¦: {source.score:.3f})"):
                            filename = source.metadata.get('filename', 'æœªçŸ¥æ–‡ä»¶')
                            st.markdown(f"**ğŸ“ æ–‡ä»¶å:** {filename}")
                            st.markdown(f"**ğŸ”— æ–‡æ¡£ID:** `{source.doc_id}`")
                            st.markdown(f"**ğŸ“ å†…å®¹:**")
                            st.text_area(
                                "å†…å®¹é¢„è§ˆ",
                                value=source.content,
                                height=150,
                                key=f"content_{i}",
                                disabled=True
                            )
                else:
                    st.warning("âš ï¸ æœªæ‰¾åˆ°ç›¸å…³æ–‡æ¡£ï¼Œè¯·æ£€æŸ¥æ˜¯å¦å·²ä¸Šä¼ ç›¸å…³å†…å®¹")
                
            except Exception as e:
                st.error(f"âŒ æŸ¥è¯¢å¤±è´¥: {str(e)}")


def render_smart_conversation_section():
    """æ¸²æŸ“æ™ºèƒ½å¯¹è¯åŒºåŸŸ - æ”¯æŒä¼šè¯ç®¡ç†å’Œæ„å›¾è¯†åˆ«"""
    st.header("ğŸ¤– æ™ºèƒ½å¯¹è¯")
    st.caption("ğŸ¯ æ™ºèƒ½åˆ¤æ–­ä½•æ—¶ä½¿ç”¨RAGæ£€ç´¢ï¼Œæ”¯æŒå¤šè½®å¯¹è¯å’Œä¼šè¯ç®¡ç†")
    
    components = st.session_state.get("components")
    if not components or not components.get("session_manager"):
        st.error("âš ï¸ ä¼šè¯ç®¡ç†å™¨æœªåˆå§‹åŒ–")
        return
    
    session_manager = components["session_manager"]
    
    # ä¼šè¯é€‰æ‹©å’Œç®¡ç†
    render_session_selector(session_manager)
    
    # è·å–å½“å‰ä¼šè¯
    current_session_id = st.session_state.get("current_session_id")
    if not current_session_id:
        st.info("ğŸ’¡ è¯·å…ˆåˆ›å»ºæˆ–é€‰æ‹©ä¸€ä¸ªä¼šè¯")
        return
    
    # æ˜¾ç¤ºå¯¹è¯å†å²
    render_conversation_history(session_manager, current_session_id)




def render_session_selector(session_manager):
    """æ¸²æŸ“ä¼šè¯é€‰æ‹©å™¨ - ä½¿ç”¨API"""
    st.subheader("ğŸ“‹ ä¼šè¯ç®¡ç†")
    
    col1, col2, col3 = st.columns([2, 1, 1])
    
    with col1:
        # ä»APIè·å–ä¼šè¯åˆ—è¡¨
        try:
            api_url = "http://localhost:8000/sessions"
            response = requests.get(api_url, params={"user_id": "anonymous", "limit": 20}, timeout=10)
            
            if response.status_code == 200:
                sessions_data = response.json()
                sessions = sessions_data.get("sessions", [])
            else:
                st.warning("âš ï¸ æ— æ³•è·å–ä¼šè¯åˆ—è¡¨ï¼Œä½¿ç”¨æœ¬åœ°æ•°æ®")
                sessions = session_manager.list_sessions(limit=20)
        
        except Exception as e:
            st.warning(f"âš ï¸ APIè°ƒç”¨å¤±è´¥ï¼Œä½¿ç”¨æœ¬åœ°æ•°æ®: {str(e)}")
            sessions = session_manager.list_sessions(limit=20)
        
        if sessions:
            session_options = {}
            for session in sessions:
                created_time = datetime.fromisoformat(session["created_at"]).strftime("%m-%d %H:%M")
                label = f"ğŸ• {created_time} | {session['title']} ({session['message_count']}æ¡)"
                session_options[label] = session["session_id"]
            
            selected_label = st.selectbox(
                "é€‰æ‹©ä¼šè¯",
                options=list(session_options.keys()),
                index=0 if st.session_state.get("current_session_id") in session_options.values() else None,
                key="session_selector"
            )
            
            if selected_label:
                selected_id = session_options[selected_label]
                if st.session_state.get("current_session_id") != selected_id:
                    st.session_state["current_session_id"] = selected_id
                    st.rerun()
        else:
            st.info("æš‚æ— ä¼šè¯")
    
    with col2:
        if st.button("â• æ–°å»ºä¼šè¯", use_container_width=True):
            try:
                # ä½¿ç”¨APIåˆ›å»ºä¼šè¯
                api_url = "http://localhost:8000/sessions"
                payload = {
                    "user_id": "anonymous",
                    "title": f"å¯¹è¯ {datetime.now().strftime('%m-%d %H:%M')}",
                    "metadata": {}
                }
                response = requests.post(api_url, json=payload, timeout=10)
                
                if response.status_code == 200:
                    result = response.json()
                    new_session_id = result["session_id"]
                    st.session_state["current_session_id"] = new_session_id
                    st.success(f"âœ… åˆ›å»ºä¼šè¯: {result['title']}")
                else:
                    # å›é€€åˆ°æœ¬åœ°åˆ›å»º
                    new_session = session_manager.create_session(
                        title=f"å¯¹è¯ {datetime.now().strftime('%m-%d %H:%M')}"
                    )
                    st.session_state["current_session_id"] = new_session.session_id
                    st.success(f"âœ… åˆ›å»ºä¼šè¯: {new_session.title}")
                
            except Exception as e:
                # å›é€€åˆ°æœ¬åœ°åˆ›å»º
                new_session = session_manager.create_session(
                    title=f"å¯¹è¯ {datetime.now().strftime('%m-%d %H:%M')}"
                )
                st.session_state["current_session_id"] = new_session.session_id
                st.success(f"âœ… åˆ›å»ºä¼šè¯: {new_session.title}")
            
            st.rerun()
    
    with col3:
        current_session_id = st.session_state.get("current_session_id")
        if current_session_id and st.button("ğŸ—‘ï¸ åˆ é™¤ä¼šè¯", use_container_width=True):
            if st.session_state.get(f"confirm_delete_session_{current_session_id}"):
                try:
                    # ä½¿ç”¨APIåˆ é™¤ä¼šè¯
                    api_url = f"http://localhost:8000/sessions/{current_session_id}"
                    response = requests.delete(api_url, params={"user_id": "anonymous"}, timeout=10)
                    
                    if response.status_code == 200:
                        st.success("âœ… ä¼šè¯å·²åˆ é™¤")
                    else:
                        # å›é€€åˆ°æœ¬åœ°åˆ é™¤
                        session_manager.delete_session(current_session_id)
                        st.success("âœ… ä¼šè¯å·²åˆ é™¤")
                
                except Exception as e:
                    # å›é€€åˆ°æœ¬åœ°åˆ é™¤
                    session_manager.delete_session(current_session_id)
                    st.success("âœ… ä¼šè¯å·²åˆ é™¤")
                
                st.session_state["current_session_id"] = None
                st.session_state[f"confirm_delete_session_{current_session_id}"] = False
                st.rerun()
            else:
                st.session_state[f"confirm_delete_session_{current_session_id}"] = True
                st.warning("âš ï¸ å†æ¬¡ç‚¹å‡»ç¡®è®¤åˆ é™¤")


def render_conversation_history(session_manager, session_id):
    """æ¸²æŸ“å¯¹è¯å†å² - ä»APIè·å–ä¼šè¯æ¶ˆæ¯"""
    try:
        # è°ƒç”¨APIè·å–ä¼šè¯å†å²
        api_url = f"http://localhost:8000/sessions/{session_id}/messages"
        response = requests.get(api_url, params={"user_id": "anonymous"}, timeout=10)
        
        if response.status_code == 200:
            result = response.json()
            messages = result.get("messages", [])
        else:
            st.warning("âš ï¸ æ— æ³•è·å–ä¼šè¯å†å²ï¼Œä½¿ç”¨æœ¬åœ°ç¼“å­˜")
            messages = session_manager.get_messages(session_id, include_system=False)
            # è½¬æ¢ä¸ºAPIæ ¼å¼
            messages = [
                {
                    "role": msg.role,
                    "content": msg.content,
                    "timestamp": msg.timestamp.isoformat() if hasattr(msg, 'timestamp') and msg.timestamp else "",
                    "metadata": msg.metadata if hasattr(msg, 'metadata') else {}
                }
                for msg in messages
            ]
    
    except Exception as e:
        st.warning(f"âš ï¸ APIè°ƒç”¨å¤±è´¥ï¼Œä½¿ç”¨æœ¬åœ°ç¼“å­˜: {str(e)}")
        messages = session_manager.get_messages(session_id, include_system=False)
        # è½¬æ¢ä¸ºAPIæ ¼å¼
        messages = [
            {
                "role": msg.role,
                "content": msg.content,
                "timestamp": msg.timestamp.isoformat() if hasattr(msg, 'timestamp') and msg.timestamp else "",
                "metadata": msg.metadata if hasattr(msg, 'metadata') else {}
            }
            for msg in messages
        ]
    
    # æ˜¾ç¤ºå¯¹è¯
    chat_container = st.container()
    with chat_container:
        for i, msg in enumerate(messages):
            if msg["role"] == "user":
                with st.chat_message("user"):
                    st.write(msg["content"])
            else:
                with st.chat_message("assistant"):
                    # æ˜¾ç¤ºå›ç­”å†…å®¹
                    st.write(msg["content"])
                    
                    # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨äº†RAGæ£€ç´¢
                    metadata = msg.get("metadata", {})
                    if metadata:
                        mode = metadata.get('mode', 'chat')
                        
                        if mode == "rag":
                            # RAGæ¨¡å¼æ ‡è¯†å’Œç»Ÿè®¡ä¿¡æ¯
                            sources_count = metadata.get('sources_count', 0)
                            st.caption(f"ğŸ” **ä½¿ç”¨äº†RAGæ£€ç´¢** | å‚è€ƒæ–‡æ¡£: {sources_count} ä¸ª")
                            
                            # æ˜¾ç¤ºæ£€ç´¢çš„chunks
                            sources = metadata.get('sources', [])
                            if sources:
                                with st.expander(f"ğŸ“– æŸ¥çœ‹æ£€ç´¢å†…å®¹ ({len(sources)}ä¸ªæ–‡æ¡£ç‰‡æ®µ)", expanded=False):
                                    for idx, source in enumerate(sources, 1):
                                        st.markdown(f"**ğŸ“„ ç‰‡æ®µ {idx}** (ç›¸ä¼¼åº¦: {source.get('score', 0):.3f})")
                                        filename = source.get('metadata', {}).get('filename', 'æœªçŸ¥æ–‡ä»¶')
                                        st.markdown(f"ğŸ“ æ¥æº: {filename}")
                                        st.text_area(
                                            f"å†…å®¹é¢„è§ˆ {idx}",
                                            value=source.get('content', ''),
                                            height=100,
                                            key=f"history_source_{session_id}_{i}_{idx}",
                                            disabled=True
                                        )
                                        if idx < len(sources):
                                            st.markdown("---")
                        else:
                            # èŠå¤©æ¨¡å¼æ ‡è¯†
                            st.caption(f"ğŸ’¬ **èŠå¤©æ¨¡å¼** | æ„å›¾: {metadata.get('intent', 'unknown')}")
                    else:
                        # å…¼å®¹æ—§æ¶ˆæ¯ï¼Œæ²¡æœ‰metadataçš„æƒ…å†µ
                        st.caption("ğŸ’¬ **èŠå¤©æ¨¡å¼** (æ—§æ¶ˆæ¯)")
                    
                    st.markdown("---")


def stream_chat_api(question: str, session_id: str = None, user_id: str = "anonymous"):
    """è°ƒç”¨æµå¼å¯¹è¯API"""
    api_url = "http://localhost:8000/conversation/stream"
    
    payload = {
        "question": question,
        "session_id": session_id,
        "user_id": user_id,
        "stream": True
    }
    
    response = requests.post(api_url, json=payload, stream=True, timeout=60)
    response.raise_for_status()
    
    return response


def handle_smart_conversation_input():
    """å¤„ç†æ™ºèƒ½å¯¹è¯è¾“å…¥ - ä½¿ç”¨æ–°çš„æµå¼API"""
    components = st.session_state.get("components")
    if not components:
        return
    
    current_session_id = st.session_state.get("current_session_id")
    
    # å¯¹è¯è¾“å…¥
    if prompt := st.chat_input("è¾“å…¥æ¶ˆæ¯...", key="smart_chat_input"):
        # æ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯
        with st.chat_message("user"):
            st.write(prompt)
        
        # ç”Ÿæˆå›ç­”
        with st.chat_message("assistant"):
            try:
                # åˆ›å»ºå®¹å™¨ç”¨äºæµå¼æ˜¾ç¤º
                answer_container = st.empty()
                metadata_container = st.empty()
                sources_container = st.empty()
                
                # è°ƒç”¨æµå¼API
                response = stream_chat_api(prompt, current_session_id, "anonymous")
                
                # å¤„ç†æµå¼å“åº”
                current_answer = ""
                session_info = {}
                sources = []
                metadata = {}
                
                for line in response.iter_lines():
                    if line:
                        line = line.decode('utf-8')
                        if line.startswith('data: '):
                            data = line[6:]
                            if data == '[DONE]':
                                break
                            
                            try:
                                parsed = json.loads(data)
                                
                                if parsed['type'] == 'session':
                                    session_info = parsed
                                    # æ›´æ–°å½“å‰ä¼šè¯ID
                                    st.session_state["current_session_id"] = parsed['session_id']
                                
                                elif parsed['type'] == 'intent':
                                    metadata.update(parsed)
                                
                                elif parsed['type'] == 'metadata':
                                    metadata.update(parsed)
                                    
                                    # æ˜¾ç¤ºæ¨¡å¼ä¿¡æ¯
                                    mode = parsed.get('mode', 'unknown')
                                    if mode == 'rag':
                                        sources_count = parsed.get('sources_count', 0)
                                        metadata_container.info(f"ğŸ” RAGæ¨¡å¼ | æ£€ç´¢åˆ° {sources_count} ä¸ªæ–‡æ¡£")
                                    else:
                                        metadata_container.info("ğŸ’¬ èŠå¤©æ¨¡å¼")
                                
                                elif parsed['type'] == 'content':
                                    current_answer += parsed['content']
                                    answer_container.markdown(current_answer)
                                
                                elif parsed['type'] == 'sources':
                                    sources = parsed['sources']
                                    
                                    # æ˜¾ç¤ºå‚è€ƒæ–‡æ¡£
                                    if sources:
                                        with sources_container.expander(f"ğŸ“– å‚è€ƒæ–‡æ¡£ ({len(sources)}ä¸ª)", expanded=False):
                                            for i, source in enumerate(sources, 1):
                                                st.markdown(f"**ğŸ“„ æ–‡æ¡£ {i}** (ç›¸ä¼¼åº¦: {source.get('score', 0):.3f})")
                                                filename = source.get('metadata', {}).get('filename', 'æœªçŸ¥æ–‡ä»¶')
                                                st.caption(f"ğŸ“ æ¥æº: {filename}")
                                                with st.container():
                                                    st.text_area(
                                                        f"å†…å®¹ {i}",
                                                        value=source.get('content', ''),
                                                        height=100,
                                                        key=f"stream_source_{i}_{session_info.get('session_id', 'temp')}",
                                                        disabled=True
                                                    )
                                                if i < len(sources):
                                                    st.markdown("---")
                                
                                elif parsed['type'] == 'error':
                                    error_msg = parsed.get('error', 'æœªçŸ¥é”™è¯¯')
                                    st.error(f"âŒ å¯¹è¯å¤±è´¥: {error_msg}")
                                    current_answer = f"æŠ±æ­‰ï¼Œå¯¹è¯å¤±è´¥: {error_msg}"
                                    break
                            
                            except json.JSONDecodeError:
                                continue
                
                # æ˜¾ç¤ºæ€§èƒ½æŒ‡æ ‡
                if metadata:
                    mode = metadata.get('mode', 'unknown')
                    confidence = metadata.get('confidence', 0)
                    
                    if mode == 'rag':
                        # RAGæ¨¡å¼çš„è¯¦ç»†æŒ‡æ ‡
                        col1, col2, col3 = st.columns(3)
                        with col1:
                            st.metric("ğŸ¯ æ„å›¾ç½®ä¿¡åº¦", f"{confidence:.2f}")
                        with col2:
                            st.metric("ğŸ“š æ£€ç´¢æ¨¡å¼", "RAG")
                        with col3:
                            st.metric("ğŸ“„ å‚è€ƒæ–‡æ¡£", len(sources))
                    else:
                        # èŠå¤©æ¨¡å¼ç®€å•æ˜¾ç¤º
                        st.caption(f"ğŸ’¬ èŠå¤©æ¨¡å¼ | æ„å›¾: {metadata.get('intent', 'unknown')}")
                
            except Exception as e:
                error_msg = f"å¯¹è¯å¤±è´¥: {str(e)}"
                st.error(f"âŒ {error_msg}")
        
        # åˆ·æ–°é¡µé¢æ˜¾ç¤ºæœ€æ–°æ¶ˆæ¯
        st.rerun()
                    




def render_stats_section():
    """æ¸²æŸ“ç»Ÿè®¡ä¿¡æ¯åŒºåŸŸ"""
    if not st.session_state.get("show_stats", False):
        return
    
    st.header("ğŸ“Š ç³»ç»Ÿç»Ÿè®¡")
    
    components = st.session_state.get("components")
    if not components:
        st.error("âš ï¸ ç³»ç»Ÿæœªå°±ç»ª")
        return
    
    try:
        # Milvusç»Ÿè®¡
        st.subheader("ğŸ—„ï¸ å‘é‡æ•°æ®åº“")
        milvus_stats = components["vector_store"].get_collection_stats()
        
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("ğŸ“š é›†åˆåç§°", milvus_stats.get("collection_name", "N/A"))
        with col2:
            st.metric("ğŸ“„ æ–‡æ¡£å—æ•°", milvus_stats.get("entity_count", 0))
        with col3:
            st.metric("ğŸ”¢ å‘é‡ç»´åº¦", milvus_stats.get("dimension", "N/A"))
        
        # æ£€ç´¢å™¨ç»Ÿè®¡
        st.subheader("ğŸ” æ£€ç´¢å™¨")
        retriever_stats = components["retriever"].get_stats()
        
        col1, col2 = st.columns(2)
        with col1:
            st.metric("âš–ï¸ ç¨ å¯†æƒé‡", f"{retriever_stats.get('dense_weight', 0):.1f}")
            st.metric("ğŸ¯ ç›¸ä¼¼åº¦é˜ˆå€¼", f"{retriever_stats.get('similarity_threshold', 0):.2f}")
        with col2:
            st.metric("ğŸ” ç¨€ç–æƒé‡", f"{retriever_stats.get('sparse_weight', 0):.1f}")
            sparse_built = "âœ…" if retriever_stats.get('sparse_index_built', False) else "âŒ"
            st.metric("ğŸ“‡ ç¨€ç–ç´¢å¼•", sparse_built)
        
        # ç”Ÿæˆå™¨ç»Ÿè®¡
        st.subheader("ğŸ¤– ç”Ÿæˆå™¨")
        generator_stats = components["generator"].get_stats()
        
        col1, col2 = st.columns(2)
        with col1:
            st.metric("ğŸ§  æ¨¡å‹", generator_stats.get("model", "N/A"))
            st.metric("ğŸ“ æœ€å¤§ä¸Šä¸‹æ–‡", generator_stats.get("max_context_length", 0))
        with col2:
            st.metric("ğŸ›ï¸ æ¸©åº¦", f"{generator_stats.get('temperature', 0):.1f}")
            st.metric("ğŸ”¢ æœ€å¤§Token", generator_stats.get("max_tokens", 0))
        
        # å¥åº·æ£€æŸ¥
        st.subheader("ğŸ¥ å¥åº·æ£€æŸ¥")
        health_info = components["vector_store"].health_check()
        
        health_data = {
            "è¿æ¥çŠ¶æ€": "âœ… æ­£å¸¸" if health_info.get("connected", False) else "âŒ å¼‚å¸¸",
            "é›†åˆå­˜åœ¨": "âœ… æ˜¯" if health_info.get("collection_exists", False) else "âŒ å¦",
            "é›†åˆåŠ è½½": "âœ… æ˜¯" if health_info.get("collection_loaded", False) else "âŒ å¦",
            "ç´¢å¼•å­˜åœ¨": "âœ… æ˜¯" if health_info.get("index_exists", False) else "âŒ å¦"
        }
        
        for key, value in health_data.items():
            st.text(f"{key}: {value}")
        
    except Exception as e:
        st.error(f"âŒ è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {str(e)}")
    
    if st.button("âŒ å…³é—­ç»Ÿè®¡"):
        st.session_state["show_stats"] = False
        st.rerun()


def render_session_management_modal():
    """æ¸²æŸ“ä¼šè¯ç®¡ç†æ¨¡æ€æ¡†"""
    if not st.session_state.get("show_session_manager", False):
        return
    
    components = st.session_state.get("components")
    if not components or not components.get("session_manager"):
        st.error("âš ï¸ ä¼šè¯ç®¡ç†å™¨æœªåˆå§‹åŒ–")
        return
    
    session_manager = components["session_manager"]
    
    st.header("ğŸ“‹ ä¼šè¯ç®¡ç†")
    
    # ä¼šè¯ç»Ÿè®¡
    st.subheader("ğŸ“Š ä¼šè¯ç»Ÿè®¡")
    stats = session_manager.get_stats()
    
    if stats:
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("ğŸ“‹ æ€»ä¼šè¯æ•°", stats.get("total_sessions", 0))
        with col2:
            st.metric("ğŸ”„ æ´»è·ƒä¼šè¯", stats.get("active_sessions", 0))
        with col3:
            st.metric("ğŸ“ å‹ç¼©ä¼šè¯", stats.get("compressed_sessions", 0))
        with col4:
            st.metric("ğŸ’¬ æ€»æ¶ˆæ¯æ•°", stats.get("total_messages", 0))
        
        # å‹ç¼©ç‡
        compression_rate = stats.get("compression_rate", 0)
        st.progress(compression_rate, text=f"å‹ç¼©ç‡: {compression_rate:.1%}")
    
    st.markdown("---")
    
    # ä¼šè¯åˆ—è¡¨ç®¡ç†
    st.subheader("ğŸ“œ ä¼šè¯åˆ—è¡¨")
    
    # æ“ä½œæŒ‰é’®
    col1, col2, col3 = st.columns(3)
    with col1:
        if st.button("ğŸ”„ åˆ·æ–°åˆ—è¡¨", use_container_width=True):
            st.rerun()
    
    with col2:
        cleanup_days = st.selectbox("æ¸…ç†å¤©æ•°", [7, 30, 90], index=1)
        if st.button(f"ğŸ§¹ æ¸…ç†{cleanup_days}å¤©å‰", use_container_width=True):
            cleaned = session_manager.cleanup_old_sessions(cleanup_days)
            st.success(f"âœ… æ¸…ç†äº† {cleaned} ä¸ªæ—§ä¼šè¯")
            st.rerun()
    
    with col3:
        if st.button("ğŸ“¥ å¯¼å…¥ä¼šè¯", use_container_width=True):
            st.session_state["show_import_dialog"] = True
    
    # ä¼šè¯åˆ—è¡¨
    sessions = session_manager.list_sessions(limit=50, include_metadata=True)
    
    if sessions:
        st.info(f"ğŸ“‹ å…±æœ‰ {len(sessions)} ä¸ªä¼šè¯")
        
        for session in sessions:
            with st.container():
                col1, col2, col3, col4, col5 = st.columns([3, 1, 1, 1, 1])
                
                with col1:
                    # ä¼šè¯ä¿¡æ¯
                    created_time = datetime.fromisoformat(session["created_at"]).strftime("%Y-%m-%d %H:%M")
                    compressed_icon = "ğŸ“" if session.get("compressed", False) else ""
                    st.markdown(f"**ğŸ“‹ {session['title']}** {compressed_icon}")
                    st.caption(f"åˆ›å»ºæ—¶é—´: {created_time} | æ¶ˆæ¯æ•°: {session['message_count']}")
                
                with col2:
                    if st.button("ğŸ“ ç¼–è¾‘", key=f"edit_{session['session_id']}"):
                        st.session_state[f"edit_title_{session['session_id']}"] = True
                
                with col3:
                    if st.button("ğŸ“¤ å¯¼å‡º", key=f"export_{session['session_id']}"):
                        # å¯¼å‡ºä¼šè¯
                        export_path = session_manager.export_session(session["session_id"], "json")
                        if export_path:
                            st.success(f"âœ… å·²å¯¼å‡ºåˆ°: {export_path}")
                        else:
                            st.error("âŒ å¯¼å‡ºå¤±è´¥")
                
                with col4:
                    if st.button("ğŸ•°ï¸ æ£€æŸ¥ç‚¹", key=f"checkpoints_{session['session_id']}"):
                        st.session_state[f"show_checkpoints_{session['session_id']}"] = True
                
                with col5:
                    if st.button("ğŸ—‘ï¸ åˆ é™¤", key=f"delete_session_{session['session_id']}"):
                        st.session_state[f"confirm_delete_session_{session['session_id']}"] = True
                
                # ç¼–è¾‘æ ‡é¢˜å¯¹è¯æ¡†
                if st.session_state.get(f"edit_title_{session['session_id']}", False):
                    new_title = st.text_input(
                        "æ–°æ ‡é¢˜",
                        value=session['title'],
                        key=f"new_title_{session['session_id']}"
                    )
                    
                    col_save, col_cancel = st.columns(2)
                    with col_save:
                        if st.button("âœ… ä¿å­˜", key=f"save_title_{session['session_id']}"):
                            if session_manager.update_session_title(session['session_id'], new_title):
                                st.success("âœ… æ ‡é¢˜å·²æ›´æ–°")
                            else:
                                st.error("âŒ æ›´æ–°å¤±è´¥")
                            st.session_state[f"edit_title_{session['session_id']}"] = False
                            st.rerun()
                    
                    with col_cancel:
                        if st.button("âŒ å–æ¶ˆ", key=f"cancel_title_{session['session_id']}"):
                            st.session_state[f"edit_title_{session['session_id']}"] = False
                            st.rerun()
                
                # æ£€æŸ¥ç‚¹ç®¡ç†
                if st.session_state.get(f"show_checkpoints_{session['session_id']}", False):
                    checkpoints = session_manager.list_checkpoints(session['session_id'])
                    
                    if checkpoints:
                        st.info(f"ğŸ•°ï¸ ä¼šè¯ '{session['title']}' çš„æ£€æŸ¥ç‚¹ ({len(checkpoints)} ä¸ª)")
                        
                        for checkpoint in checkpoints:
                            checkpoint_time = datetime.fromisoformat(checkpoint["created_at"]).strftime("%m-%d %H:%M")
                            file_size = checkpoint["file_size"] / 1024  # KB
                            
                            st.markdown(f"**ğŸ•°ï¸ {checkpoint_time}** | {checkpoint['message_count']} æ¶ˆæ¯ | {file_size:.1f}KB")
                            
                            if st.button("ğŸ”„ æ¢å¤", key=f"restore_{checkpoint['checkpoint_id']}"):
                                restored = session_manager.restore_from_checkpoint(session['session_id'], checkpoint['checkpoint_id'])
                                if restored:
                                    st.success("âœ… ä¼šè¯å·²æ¢å¤")
                                    st.rerun()
                                else:
                                    st.error("âŒ æ¢å¤å¤±è´¥")
                    else:
                        st.info("ğŸ’­ æš‚æ— æ£€æŸ¥ç‚¹")
                    
                    if st.button("âŒ å…³é—­æ£€æŸ¥ç‚¹", key=f"close_checkpoints_{session['session_id']}"):
                        st.session_state[f"show_checkpoints_{session['session_id']}"] = False
                        st.rerun()
                
                st.markdown("---")
    else:
        st.info("ğŸ’­ æš‚æ— ä¼šè¯")
    
    # å¯¼å…¥å¯¹è¯æ¡†
    if st.session_state.get("show_import_dialog", False):
        st.subheader("ğŸ“¥ å¯¼å…¥ä¼šè¯")
        
        uploaded_file = st.file_uploader(
            "é€‰æ‹©ä¼šè¯æ–‡ä»¶",
            type=['json'],
            help="æ”¯æŒJSONæ ¼å¼çš„ä¼šè¯æ–‡ä»¶"
        )
        
        if uploaded_file:
            col_import, col_cancel = st.columns(2)
            
            with col_import:
                if st.button("ğŸ“¥ å¼€å§‹å¯¼å…¥", type="primary"):
                    # ä¿å­˜ä¸´æ—¶æ–‡ä»¶
                    temp_path = Path("temp") / uploaded_file.name
                    temp_path.parent.mkdir(exist_ok=True)
                    
                    with open(temp_path, "wb") as f:
                        f.write(uploaded_file.read())
                    
                    # å¯¼å…¥ä¼šè¯
                    components = st.session_state.get("components")
                    if components and "session_manager" in components:
                        new_session_id = components["session_manager"].import_session(str(temp_path))
                    else:
                        st.error("âŒ ä¼šè¯ç®¡ç†å™¨æœªåˆå§‹åŒ–")
                        new_session_id = None
                    
                    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                    try:
                        temp_path.unlink()
                    except:
                        pass
                    
                    if new_session_id:
                        st.success(f"âœ… ä¼šè¯å¯¼å…¥æˆåŠŸ: {new_session_id}")
                        st.session_state["show_import_dialog"] = False
                        st.rerun()
                    else:
                        st.error("âŒ å¯¼å…¥å¤±è´¥")
            
            with col_cancel:
                if st.button("âŒ å–æ¶ˆå¯¼å…¥"):
                    st.session_state["show_import_dialog"] = False
                    st.rerun()
    
    # å…³é—­æŒ‰é’®
    if st.button("âŒ å…³é—­ä¼šè¯ç®¡ç†"):
        st.session_state["show_session_manager"] = False
        st.rerun()


def fetch_documents(vector_store):
    """è·å–æ–‡æ¡£åˆ—è¡¨"""
    try:
        if not vector_store.collection:
            return {"documents": [], "total": 0}
        
        # å¤ç”¨ç»Ÿä¸€çš„æ–‡æ¡£ç»Ÿè®¡é€»è¾‘
        stats = fetch_knowledge_stats(vector_store)
        if not stats.get("total_documents"):
            return {"documents": [], "total": 0}
        
        # è·å–æ‰€æœ‰chunkså¹¶åˆ†ç»„
        search_results = vector_store.collection.query(
            expr="doc_id != ''",
            output_fields=["doc_id", "content", "metadata", "chunk_index"],
            limit=10000
        )
        
        # æŒ‰æ–‡æ¡£åˆ†ç»„
        doc_chunks = {}
        for result in search_results:
            doc_id = result.get('doc_id')
            if doc_id:
                if doc_id not in doc_chunks:
                    doc_chunks[doc_id] = []
                doc_chunks[doc_id].append(result)
        
        # æ„å»ºæ–‡æ¡£ä¿¡æ¯
        docs = []
        for doc_id, chunks in doc_chunks.items():
            if chunks:
                # ä½¿ç”¨ç¬¬ä¸€ä¸ªchunkçš„metadataä½œä¸ºæ–‡æ¡£ä¿¡æ¯
                first_chunk = chunks[0]
                try:
                    metadata = json.loads(first_chunk.get('metadata', '{}'))
                except:
                    metadata = {}
                
                # è®¡ç®—æ€»å†…å®¹é•¿åº¦ç”¨äºé¢„è§ˆ
                total_content = " ".join([chunk.get('content', '') for chunk in chunks])
                preview = total_content[:200] + '...' if len(total_content) > 200 else total_content
                
                docs.append({
                    "doc_id": doc_id,
                    "filename": metadata.get('filename', 'æœªçŸ¥æ–‡ä»¶'),
                    "file_type": metadata.get('file_type', 'unknown'),
                    "file_size": metadata.get('file_size', 0),
                    "created_time": metadata.get('created_time', 0),
                    "modified_time": metadata.get('modified_time', 0),
                    "preview": preview,
                    "chunk_count": len(chunks)
                })
        
        return {"documents": docs, "total": len(docs)}
        
    except Exception as e:
        st.error(f"è·å–æ–‡æ¡£åˆ—è¡¨å¤±è´¥: {str(e)}")
        return {"documents": [], "total": 0}


def fetch_knowledge_stats(vector_store):
    """è·å–çŸ¥è¯†åº“ç»Ÿè®¡"""
    try:
        if not vector_store.collection:
            return {}
        
        # è·å–åŸºç¡€ç»Ÿè®¡
        collection_stats = vector_store.get_collection_stats()
        
        # è·å–æ‰€æœ‰chunks
        all_chunks = vector_store.collection.query(
            expr="doc_id != ''",
            output_fields=["doc_id", "metadata"],
            limit=10000
        )
        
        # åŸºäºæ–‡æ¡£çº§åˆ«è¿›è¡Œç»Ÿè®¡
        documents = {}  # doc_id -> metadata
        for chunk in all_chunks:
            doc_id = chunk.get('doc_id')
            if not doc_id:
                continue
                
            try:
                import json
                metadata = json.loads(chunk.get('metadata', '{}'))
                
                # åªå­˜å‚¨æ¯ä¸ªæ–‡æ¡£çš„ç¬¬ä¸€ä¸ªchunkçš„metadata
                if doc_id not in documents:
                    documents[doc_id] = metadata
                    
            except:
                continue
        
        # æ–‡æ¡£æ€»æ•°
        doc_count = len(documents)
        
        # æ–‡ä»¶ç±»å‹ç»Ÿè®¡ï¼ˆåŸºäºæ–‡æ¡£çº§åˆ«ï¼‰
        file_types = {}
        for metadata in documents.values():
            file_type = metadata.get('file_type', 'unknown')
            file_types[file_type] = file_types.get(file_type, 0) + 1
        
        # å®é™…chunksæ•°é‡ï¼ˆå»é‡åçš„çœŸå®æ–‡æ¡£å—æ•°ï¼‰
        actual_chunks = len(all_chunks)
        
        return {
            "total_documents": doc_count,
            "total_chunks": actual_chunks,  # æ˜¾ç¤ºçœŸå®chunksæ•°é‡
            "file_types": file_types,
            "collection_name": collection_stats.get("collection_name"),
            "dimension": collection_stats.get("dimension"),
            "index_type": collection_stats.get("index_type")
        }
        
    except Exception as e:
        st.error(f"è·å–çŸ¥è¯†åº“ç»Ÿè®¡å¤±è´¥: {str(e)}")
        return {}


def search_documents(vector_store, query: str, limit: int = 10):
    """æœç´¢æ–‡æ¡£ - ä½¿ç”¨å‘é‡æ£€ç´¢è€Œä¸æ˜¯LIKEæŸ¥è¯¢"""
    try:
        if not vector_store.collection:
            return {"results": [], "total": 0}
        
        # è·å–ç³»ç»Ÿç»„ä»¶è¿›è¡Œå‘é‡æ£€ç´¢
        components = st.session_state.get("components")
        if not components or not components.get("retriever"):
            # é™çº§æ–¹æ¡ˆï¼šè·å–æ‰€æœ‰æ–‡æ¡£ç„¶ååœ¨å†…å­˜ä¸­è¿‡æ»¤
            all_results = vector_store.collection.query(
                expr="doc_id != ''",
                output_fields=["id", "doc_id", "content", "metadata", "chunk_index"],
                limit=1000  # è·å–æ›´å¤šæ–‡æ¡£ç”¨äºè¿‡æ»¤
            )
            
            # åœ¨å†…å­˜ä¸­è¿›è¡Œç®€å•çš„æ–‡æœ¬åŒ¹é…
            search_results = []
            query_lower = query.lower()
            
            for result in all_results:
                content = result.get('content', '')
                if query_lower in content.lower():
                    try:
                        import json
                        metadata = json.loads(result.get('metadata', '{}'))
                        
                        search_results.append({
                            "id": result.get('id'),
                            "doc_id": result.get('doc_id'),
                            "filename": metadata.get('filename', 'æœªçŸ¥æ–‡ä»¶'),
                            "content": content,
                            "chunk_index": result.get('chunk_index', 0),
                            "highlight": content.replace(query, f"**{query}**")
                        })
                        
                        if len(search_results) >= limit:
                            break
                    except:
                        continue
            
            return {"results": search_results, "total": len(search_results), "query": query}
        
        else:
            # ä½¿ç”¨å‘é‡æ£€ç´¢å™¨è¿›è¡Œæ™ºèƒ½æœç´¢
            retriever = components["retriever"]
            retrieval_result = retriever.search(
                query=query,
                top_k=limit,
                method="hybrid"
            )
            
            search_results = []
            for hit in retrieval_result.hits:
                search_results.append({
                    "id": hit.id,
                    "doc_id": hit.doc_id,
                    "filename": hit.metadata.get('filename', 'æœªçŸ¥æ–‡ä»¶'),
                    "content": hit.content,
                    "chunk_index": hit.chunk_index,
                    "highlight": hit.content.replace(query, f"**{query}**"),
                    "score": hit.score
                })
            
            return {"results": search_results, "total": len(search_results), "query": query}
        
    except Exception as e:
        st.error(f"æœç´¢æ–‡æ¡£å¤±è´¥: {str(e)}")
        return {"results": [], "total": 0}


def get_document_detail(vector_store, doc_id: str):
    """è·å–æ–‡æ¡£è¯¦ç»†ä¿¡æ¯"""
    try:
        if not vector_store.collection:
            return None
        
        # æŸ¥è¯¢è¯¥æ–‡æ¡£çš„æ‰€æœ‰å—
        chunks = vector_store.collection.query(
            expr=f'doc_id == "{doc_id}"',
            output_fields=["id", "content", "metadata", "chunk_index"],
            limit=1000
        )
        
        if not chunks:
            return None
        
        # æŒ‰chunk_indexæ’åº
        chunks.sort(key=lambda x: x.get('chunk_index', 0))
        
        # è§£æç¬¬ä¸€ä¸ªå—çš„metadataä½œä¸ºæ–‡æ¡£metadata
        import json
        try:
            doc_metadata = json.loads(chunks[0].get('metadata', '{}'))
        except:
            doc_metadata = {}
        
        # æ„å»ºå“åº”
        doc_info = {
            "doc_id": doc_id,
            "filename": doc_metadata.get('filename', 'æœªçŸ¥æ–‡ä»¶'),
            "file_type": doc_metadata.get('file_type', 'unknown'),
            "file_size": doc_metadata.get('file_size', 0),
            "created_time": doc_metadata.get('created_time', 0),
            "modified_time": doc_metadata.get('modified_time', 0),
            "chunk_count": len(chunks),
            "chunks": []
        }
        
        for chunk in chunks:
            try:
                chunk_metadata = json.loads(chunk.get('metadata', '{}'))
            except:
                chunk_metadata = {}
                
            doc_info["chunks"].append({
                "id": chunk.get('id'),
                "content": chunk.get('content', ''),
                "chunk_index": chunk.get('chunk_index', 0),
                "chunk_length": chunk_metadata.get('chunk_length', 0)
            })
        
        return doc_info
        
    except Exception as e:
        st.error(f"è·å–æ–‡æ¡£è¯¦æƒ…å¤±è´¥: {str(e)}")
        return None


def delete_document(vector_store, doc_id: str):
    """åˆ é™¤æ–‡æ¡£"""
    try:
        import logging
        logger = logging.getLogger(__name__)
        
        logger.info(f"å¼€å§‹åˆ é™¤æ–‡æ¡£: {doc_id}")
        
        # æ£€æŸ¥æ–‡æ¡£æ˜¯å¦å­˜åœ¨
        if not vector_store.collection:
            st.error("âŒ å‘é‡æ•°æ®åº“è¿æ¥æœªåˆå§‹åŒ–")
            return False
        
        # å…ˆæŸ¥è¯¢æ–‡æ¡£æ˜¯å¦å­˜åœ¨
        expr = f'doc_id == "{doc_id}"'
        existing_docs = vector_store.collection.query(
            expr=expr,
            output_fields=["id"],
            limit=1
        )
        
        if not existing_docs:
            st.info("â„¹ï¸ æ–‡æ¡£å·²ä¸å­˜åœ¨äºæ•°æ®åº“ä¸­")
            return True
        
        # æ‰§è¡Œåˆ é™¤
        result = vector_store.delete_by_doc_id(doc_id)
        
        if result:
            logger.info(f"æ–‡æ¡£åˆ é™¤æˆåŠŸ: {doc_id}")
        else:
            logger.error(f"æ–‡æ¡£åˆ é™¤å¤±è´¥: {doc_id}")
        
        return result
        
    except Exception as e:
        import logging
        logger = logging.getLogger(__name__)
        logger.error(f"åˆ é™¤æ–‡æ¡£å¼‚å¸¸: {doc_id}, é”™è¯¯: {str(e)}")
        st.error(f"åˆ é™¤æ–‡æ¡£å¤±è´¥: {str(e)}")
        return False


def render_knowledge_management():
    """æ¸²æŸ“çŸ¥è¯†åº“ç®¡ç†ç•Œé¢"""
    st.header("ğŸ“š çŸ¥è¯†åº“ç®¡ç†")
    
    components = st.session_state.get("components")
    if not components:
        st.error("âš ï¸ ç³»ç»Ÿæœªå°±ç»ªï¼Œæ— æ³•ç®¡ç†çŸ¥è¯†åº“")
        return
    
    vector_store = components["vector_store"]
    
    # çŸ¥è¯†åº“ç»Ÿè®¡
    st.subheader("ğŸ“Š çŸ¥è¯†åº“ç»Ÿè®¡")
    
    stats = fetch_knowledge_stats(vector_store)
    if stats:
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("ğŸ“š æ–‡æ¡£æ€»æ•°", stats.get("total_documents", 0))
        with col2:
            st.metric("ğŸ“„ æ–‡æ¡£å—æ•°", stats.get("total_chunks", 0))
        with col3:
            st.metric("ğŸ”¢ å‘é‡ç»´åº¦", stats.get("dimension", "N/A"))
        with col4:
            st.metric("ğŸ“‡ ç´¢å¼•ç±»å‹", stats.get("index_type", "N/A"))
        
        # æ–‡ä»¶ç±»å‹åˆ†å¸ƒ
        if stats.get("file_types"):
            st.subheader("ğŸ“ æ–‡ä»¶ç±»å‹åˆ†å¸ƒ")
            file_types = stats["file_types"]
            
            # æ˜¾ç¤ºä¸ºå›¾è¡¨
            if file_types:
                cols = st.columns(len(file_types))
                for i, (file_type, count) in enumerate(file_types.items()):
                    with cols[i]:
                        st.metric(f"ğŸ“„ {file_type.upper()}", count)
    
    st.markdown("---")
    
    # æœç´¢åŠŸèƒ½
    st.subheader("ğŸ” æœç´¢æ–‡æ¡£")
    col1, col2 = st.columns([4, 1])
    
    with col1:
        search_query = st.text_input("æœç´¢å…³é”®è¯", placeholder="è¾“å…¥è¦æœç´¢çš„å†…å®¹...")
    
    with col2:
        search_limit = st.selectbox("ç»“æœæ•°é‡", [5, 10, 20, 50], index=1)
    
    if search_query:
        with st.spinner("ğŸ” æœç´¢ä¸­..."):
            search_results = search_documents(vector_store, search_query, search_limit)
        
        if search_results["results"]:
            st.success(f"ğŸ¯ æ‰¾åˆ° {search_results['total']} ä¸ªç»“æœ")
            
            for i, result in enumerate(search_results["results"], 1):
                with st.expander(f"ğŸ“„ {result['filename']} - å— {result['chunk_index']} (ç›¸å…³åº¦è¾ƒé«˜)"):
                    st.markdown(f"**æ–‡æ¡£ID:** `{result['doc_id']}`")
                    st.markdown(f"**æ–‡ä»¶å:** {result['filename']}")
                    st.markdown(f"**å—ç´¢å¼•:** {result['chunk_index']}")
                    st.markdown("**å†…å®¹é¢„è§ˆ:**")
                    st.text_area("", value=result['content'], height=100, key=f"search_content_{i}", disabled=True)
        else:
            st.warning("ğŸ˜” æœªæ‰¾åˆ°ç›¸å…³å†…å®¹")
    
    st.markdown("---")
    
    # æ–‡æ¡£åˆ—è¡¨
    st.subheader("ğŸ“‹ æ–‡æ¡£åˆ—è¡¨")
    
    # åˆ·æ–°æŒ‰é’®
    col1, col2, col3 = st.columns([1, 1, 4])
    with col1:
        if st.button("ğŸ”„ åˆ·æ–°åˆ—è¡¨"):
            st.rerun()
    
    with col2:
        show_details = st.checkbox("æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯", value=False)
    
    # è·å–æ–‡æ¡£åˆ—è¡¨
    with st.spinner("ğŸ“š åŠ è½½æ–‡æ¡£åˆ—è¡¨..."):
        docs_data = fetch_documents(vector_store)
    
    if docs_data["documents"]:
        st.info(f"ğŸ“š å…±æœ‰ {docs_data['total']} ä¸ªæ–‡æ¡£")
        
        for doc in docs_data["documents"]:
            with st.container():
                # æ–‡æ¡£åŸºæœ¬ä¿¡æ¯
                col1, col2, col3, col4 = st.columns([3, 1, 1, 1])
                
                with col1:
                    st.markdown(f"**ğŸ“„ {doc['filename']}**")
                    if show_details:
                        st.caption(f"ID: `{doc['doc_id']}`")
                        st.caption(f"ç±»å‹: {doc['file_type']} | å¤§å°: {doc['file_size']} bytes")
                        if doc['created_time']:
                            created_time = datetime.fromtimestamp(doc['created_time']).strftime("%Y-%m-%d %H:%M")
                            st.caption(f"åˆ›å»ºæ—¶é—´: {created_time}")
                
                with col2:
                    if st.button("ğŸ” æŸ¥çœ‹", key=f"view_{doc['doc_id']}"):
                        st.session_state[f"show_detail_{doc['doc_id']}"] = True
                
                with col3:
                    if st.button("ğŸ—‘ï¸ åˆ é™¤", key=f"delete_{doc['doc_id']}", type="secondary"):
                        st.session_state[f"confirm_delete_{doc['doc_id']}"] = True
                
                with col4:
                    # æ–‡ä»¶ç±»å‹å›¾æ ‡
                    file_type = doc['file_type'].lower()
                    if file_type == '.pdf':
                        st.markdown("ğŸ“•")
                    elif file_type == '.docx':
                        st.markdown("ğŸ“˜")
                    elif file_type in ['.txt', '.md']:
                        st.markdown("ğŸ“„")
                    else:
                        st.markdown("ğŸ“‹")
                
                # å†…å®¹é¢„è§ˆ
                if show_details and doc.get('preview'):
                    st.text_area(
                        "å†…å®¹é¢„è§ˆ",
                        value=doc['preview'],
                        height=80,
                        key=f"preview_{doc['doc_id']}",
                        disabled=True
                    )
                
                # ç¡®è®¤åˆ é™¤å¯¹è¯æ¡†
                if st.session_state.get(f"confirm_delete_{doc['doc_id']}", False):
                    st.warning(f"âš ï¸ ç¡®è®¤åˆ é™¤æ–‡æ¡£ '{doc['filename']}'ï¼Ÿæ­¤æ“ä½œä¸å¯æ’¤é”€ï¼")
                    col_yes, col_no = st.columns(2)
                    
                    with col_yes:
                        if st.button("âœ… ç¡®è®¤åˆ é™¤", key=f"confirm_yes_{doc['doc_id']}", type="primary"):
                            with st.spinner("ğŸ—‘ï¸ åˆ é™¤ä¸­ï¼Œè¯·ç¨å€™..."):
                                success = delete_document(vector_store, doc['doc_id'])
                                if success:
                                    # æ¸…ç†ç›¸å…³çš„session state
                                    st.session_state[f"confirm_delete_{doc['doc_id']}"] = False
                                    if f"show_detail_{doc['doc_id']}" in st.session_state:
                                        del st.session_state[f"show_detail_{doc['doc_id']}"]
                                    
                                    st.success("âœ… æ–‡æ¡£åˆ é™¤æˆåŠŸ")
                                    
                                    
                                    time.sleep(1)  # è®©ç”¨æˆ·çœ‹åˆ°æˆåŠŸæ¶ˆæ¯
                                    st.rerun()
                                else:
                                    st.error("âŒ æ–‡æ¡£åˆ é™¤å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•")
                                    st.session_state[f"confirm_delete_{doc['doc_id']}"] = False
                    
                    with col_no:
                        if st.button("âŒ å–æ¶ˆ", key=f"confirm_no_{doc['doc_id']}"):
                            st.session_state[f"confirm_delete_{doc['doc_id']}"] = False
                            st.rerun()
                
                # è¯¦ç»†ä¿¡æ¯å¯¹è¯æ¡†
                if st.session_state.get(f"show_detail_{doc['doc_id']}", False):
                    with st.spinner("ğŸ“„ åŠ è½½æ–‡æ¡£è¯¦æƒ…..."):
                        doc_detail = get_document_detail(vector_store, doc['doc_id'])
                    
                    if doc_detail:
                        st.info(f"ğŸ“„ **{doc_detail['filename']}** è¯¦ç»†ä¿¡æ¯")
                        
                        # åŸºæœ¬ä¿¡æ¯
                        detail_col1, detail_col2 = st.columns(2)
                        with detail_col1:
                            st.text(f"æ–‡æ¡£ID: {doc_detail['doc_id']}")
                            st.text(f"æ–‡ä»¶ç±»å‹: {doc_detail['file_type']}")
                            st.text(f"æ–‡ä»¶å¤§å°: {doc_detail['file_size']} bytes")
                        
                        with detail_col2:
                            st.text(f"æ–‡æ¡£å—æ•°: {doc_detail['chunk_count']}")
                            if doc_detail['created_time']:
                                created = datetime.fromtimestamp(doc_detail['created_time']).strftime("%Y-%m-%d %H:%M:%S")
                                st.text(f"åˆ›å»ºæ—¶é—´: {created}")
                        
                        # æ–‡æ¡£å—åˆ—è¡¨
                        if doc_detail['chunks']:
                            st.markdown("**ğŸ“ æ–‡æ¡£å—å†…å®¹:**")
                            
                            for chunk in doc_detail['chunks']:
                                with st.expander(f"ğŸ“„ å— {chunk['chunk_index']} ({chunk['chunk_length']} å­—ç¬¦)"):
                                    st.text_area(
                                        "å†…å®¹",
                                        value=chunk['content'],
                                        height=200,
                                        key=f"chunk_{chunk['id']}",
                                        disabled=True
                                    )
                    else:
                        st.error("âŒ æ— æ³•è·å–æ–‡æ¡£è¯¦æƒ…")
                    
                    if st.button("âŒ å…³é—­è¯¦æƒ…", key=f"close_detail_{doc['doc_id']}"):
                        st.session_state[f"show_detail_{doc['doc_id']}"] = False
                        st.rerun()
                
                st.markdown("---")
    
    else:
        st.info("ğŸ“­ æš‚æ— æ–‡æ¡£ï¼Œè¯·å…ˆä¸Šä¼ ä¸€äº›æ–‡æ¡£")
    
    # æ‰¹é‡æ“ä½œ
    st.subheader("ğŸ”§ æ‰¹é‡æ“ä½œ")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.empty()  # å ä½ç¬¦
    
    with col2:
        if st.button("ğŸ“Š æŸ¥çœ‹ç³»ç»Ÿç»Ÿè®¡", type="secondary"):
            st.session_state["show_stats"] = True


def main():
    """ä¸»å‡½æ•°"""
    # åˆå§‹åŒ–ç³»ç»Ÿ
    if "components" not in st.session_state:
        with st.spinner("ğŸš€ ç³»ç»Ÿåˆå§‹åŒ–ä¸­..."):
            st.session_state.components = initialize_system()
    
    # åˆå§‹åŒ–å½“å‰é¡µé¢çŠ¶æ€
    if "current_page" not in st.session_state:
        st.session_state.current_page = "upload"
    
    # æ¸²æŸ“ä¾§è¾¹æ 
    render_sidebar()
    
    # ä¸»å†…å®¹åŒºåŸŸ
    if not st.session_state.get("components"):
        st.error("âŒ ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®å’ŒæœåŠ¡çŠ¶æ€")
        st.stop()
    
    # ä½¿ç”¨æŒ‰é’®å¯¼èˆªä»£æ›¿tabsï¼Œé˜²æ­¢è‡ªåŠ¨è·³è½¬
    st.markdown("### å¯¼èˆª")
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        if st.button("ğŸ“¤ æ–‡æ¡£ä¸Šä¼ ", use_container_width=True, 
                     type="primary" if st.session_state.current_page == "upload" else "secondary"):
            st.session_state.current_page = "upload"
            st.rerun()
    
    with col2:
        if st.button("ğŸ” æ™ºèƒ½é—®ç­”", use_container_width=True, 
                     type="primary" if st.session_state.current_page == "query" else "secondary"):
            st.session_state.current_page = "query"
            st.rerun()
    
    with col3:
        if st.button("ğŸ¤– æ™ºèƒ½å¯¹è¯", use_container_width=True, 
                     type="primary" if st.session_state.current_page == "smart_chat" else "secondary"):
            st.session_state.current_page = "smart_chat"
            st.rerun()
    
    with col4:
        if st.button("ğŸ“š çŸ¥è¯†åº“ç®¡ç†", use_container_width=True, 
                     type="primary" if st.session_state.current_page == "knowledge" else "secondary"):
            st.session_state.current_page = "knowledge"
            st.rerun()
    
    st.markdown("---")
    
    # æ ¹æ®å½“å‰é¡µé¢æ¸²æŸ“å¯¹åº”å†…å®¹
    if st.session_state.current_page == "upload":
        render_upload_section()
    elif st.session_state.current_page == "query":
        render_query_section()
    elif st.session_state.current_page == "smart_chat":
        render_smart_conversation_section()
        handle_smart_conversation_input()
    elif st.session_state.current_page == "knowledge":
        render_knowledge_management()
    
    # ç»Ÿè®¡ä¿¡æ¯ï¼ˆæ¨¡æ€æ¡†å¼ï¼‰
    render_stats_section()
    
    # ä¼šè¯ç®¡ç†ï¼ˆæ¨¡æ€æ¡†å¼ï¼‰
    render_session_management_modal()
    
    # é¡µè„š
    st.markdown("---")
    st.markdown("""
    <div style='text-align: center; color: #666;'>
        ğŸ¤– LLM RAG æ™ºèƒ½é—®ç­”ç³»ç»Ÿ | åŸºäº Milvus + Kimi + SiliconFlow
    </div>
    """, unsafe_allow_html=True)


if __name__ == "__main__":
    main()